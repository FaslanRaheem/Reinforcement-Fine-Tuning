{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "969cf2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "print(os.environ.get(\"https://serving.app.predibase.com/4e5be602/deployments/v2/llms/my-qwen/generate\"))  # Should print the real URL\n",
    "print(os.environ.get(\"pb_CBZccy_QUru6_eFpvrTlYQ\"))         # Should print the real key (or ****)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "540bdc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables\n",
    "_ = load_dotenv()\n",
    "\n",
    "# Use them in the OpenAI client\n",
    "client = OpenAI(\n",
    "    base_url=\"https://serving.app.predibase.com/4e5be602/deployments/v2/llms/my-qwen/generate\",\n",
    "    api_key=\"pb_CBZccy_QUru6_eFpvrTlYQ\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ee0cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohomed Faslan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "base_model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3ca76d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are playing Wordle, a word-guessing game.\n",
    "\n",
    "### Game Rules:\n",
    "- You have **6 tries** to guess a secret **5-letter** word.\n",
    "- Each guess must be a valid **5-letter English word**.\n",
    "- After each guess, you will receive feedback indicating how close \n",
    "your guess was.\n",
    "\n",
    "### Feedback Format:\n",
    "Each letter in your guess will receive one of three symbols:\n",
    "1. ‚úì : The letter is in the word and in the CORRECT position.\n",
    "2. - : The letter is in the word but in the WRONG position.\n",
    "3. x : The letter is NOT in the word.\n",
    "\n",
    "### Example:\n",
    "Secret Word: BRISK\n",
    "\n",
    "Guess 1: STORM ‚Üí Feedback: S(-) T(x) O(x) R(-) M(x)\n",
    "Guess 2: BRAVE ‚Üí Feedback: B(‚úì) R(‚úì) A(x) V(x) E(x)\n",
    "Guess 3: BRISK ‚Üí Feedback: B(‚úì) R(‚úì) I(‚úì) S(‚úì) K(‚úì)\n",
    "\n",
    "### Response Format:\n",
    "Think through the problem and feedback step by step. Make sure to \n",
    "first add your step by step thought process within <think> </think> \n",
    "tags. Then, return your guessed word in the following format: \n",
    "<guess> guessed-word </guess>.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5e5b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class LetterFeedback(Enum):\n",
    "    CORRECT = \"‚úì\"\n",
    "    WRONG_POS = \"-\"\n",
    "    WRONG_LETTER = \"x\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GuessWithFeedback:\n",
    "    guess: str\n",
    "    feedback: List[LetterFeedback]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"Returns a readable string showing the guess alongside\n",
    "        its letter-by-letter feedback.\"\"\"\n",
    "        feedback_str = \" \".join(f\"{letter}({fb.value})\" for letter, fb in zip(self.guess, self.feedback))\n",
    "        return f\"{self.guess} ‚Üí Feedback: {feedback_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c6c77fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_user_prompt(past_guesses: List[GuessWithFeedback]) -> str:\n",
    "    \"\"\"Creates a user-facing prompt that includes past guesses \n",
    "    and their feedback.\"\"\"\n",
    "    prompt = \"Make a new 5-letter word guess.\"\n",
    "    if past_guesses:\n",
    "        prompt += \"\\n\\nHere is some previous feedback:\"\n",
    "        for i, guess in enumerate(past_guesses):\n",
    "            prompt += f\"\\nGuess {i+1}: {guess}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05d4ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prompt(past_guesses: List[GuessWithFeedback]):\n",
    "    \"\"\"Formats a full chat prompt using a system message, user \n",
    "    prompt, and assistant preamble to start the model's \n",
    "    step-by-step reasoning.\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": render_user_prompt(past_guesses)\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Let me solve this step by step.\\n<think>\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, continue_final_message=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e25da23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stream(prompt: str, adapter_id: str = \"myqwen\") -> str:\n",
    "    \"\"\"Streams a model-generated response from a prompt in real-time and prints it as it arrives.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=adapter_id,\n",
    "        prompt=prompt,\n",
    "        temperature=0.0,\n",
    "        max_tokens=2048,\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    completion = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].text is not None:\n",
    "            content = chunk.choices[0].text\n",
    "            print(content, end=\"\", flush=True)\n",
    "            completion += content\n",
    "    print()\n",
    "\n",
    "    return completion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "800ab9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "\n",
      "You are playing Wordle, a word-guessing game.\n",
      "\n",
      "### Game Rules:\n",
      "- You have **6 tries** to guess a secret **5-letter** word.\n",
      "- Each guess must be a valid **5-letter English word**.\n",
      "- After each guess, you will receive feedback indicating how close \n",
      "your guess was.\n",
      "\n",
      "### Feedback Format:\n",
      "Each letter in your guess will receive one of three symbols:\n",
      "1. ‚úì : The letter is in the word and in the CORRECT position.\n",
      "2. - : The letter is in the word but in the WRONG position.\n",
      "3. x : The letter is NOT in the word.\n",
      "\n",
      "### Example:\n",
      "Secret Word: BRISK\n",
      "\n",
      "Guess 1: STORM ‚Üí Feedback: S(-) T(x) O(x) R(-) M(x)\n",
      "Guess 2: BRAVE ‚Üí Feedback: B(‚úì) R(‚úì) A(x) V(x) E(x)\n",
      "Guess 3: BRISK ‚Üí Feedback: B(‚úì) R(‚úì) I(‚úì) S(‚úì) K(‚úì)\n",
      "\n",
      "### Response Format:\n",
      "Think through the problem and feedback step by step. Make sure to \n",
      "first add your step by step thought process within <think> </think> \n",
      "tags. Then, return your guessed word in the following format: \n",
      "<guess> guessed-word </guess>.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Make a new 5-letter word guess.\n",
      "\n",
      "Here is some previous feedback:\n",
      "Guess 1: CRANE ‚Üí Feedback: C(‚úì) R(‚úì) A(‚úì) N(x) E(x)\n",
      "Guess 2: CRASH ‚Üí Feedback: C(‚úì) R(‚úì) A(‚úì) S(x) H(x)<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "secret_word = \"CRAFT\"\n",
    "\n",
    "past_guesses = [\n",
    "    GuessWithFeedback(\n",
    "        \"CRANE\", [\n",
    "            LetterFeedback.CORRECT, \n",
    "            LetterFeedback.CORRECT, \n",
    "            LetterFeedback.CORRECT, \n",
    "            LetterFeedback.WRONG_LETTER, \n",
    "            LetterFeedback.WRONG_LETTER,\n",
    "        ]),\n",
    "    GuessWithFeedback(\n",
    "        \"CRASH\", [\n",
    "            LetterFeedback.CORRECT, \n",
    "            LetterFeedback.CORRECT, \n",
    "            LetterFeedback.CORRECT, \n",
    "            LetterFeedback.WRONG_LETTER, \n",
    "            LetterFeedback.WRONG_LETTER,\n",
    "        ]),\n",
    "]\n",
    "\n",
    "prompt = render_prompt(past_guesses)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de67baed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m base_completion = \u001b[43mgenerate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mgenerate_stream\u001b[39m\u001b[34m(prompt, adapter_id)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_stream\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, adapter_id: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mmyqwen\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Streams a model-generated response from a prompt in real-time and prints it as it arrives.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     response = \u001b[43mclient\u001b[49m.chat.completions.create(\n\u001b[32m      4\u001b[39m         model=adapter_id,\n\u001b[32m      5\u001b[39m         prompt=prompt,\n\u001b[32m      6\u001b[39m         temperature=\u001b[32m0.0\u001b[39m,\n\u001b[32m      7\u001b[39m         max_tokens=\u001b[32m2048\u001b[39m,\n\u001b[32m      8\u001b[39m         stream=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     11\u001b[39m     completion = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "\u001b[31mNameError\u001b[39m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "base_completion = generate_stream(prompt=str, adapter_id=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "741034b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (368114538.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mft_completion = generate_stream(\"Explain supervised learning in simple terms.\", adapter_id:\"myqwen\")\u001b[39m\n                                                                                              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# prompt fine-tuned model\n",
    "ft_completion = generate_stream(\"Explain supervised learning in simple terms.\", adapter_id:\"myqwen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "066c4a13",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_feedback\u001b[39m(guess: \u001b[38;5;28mstr\u001b[39m, secret_word: \u001b[38;5;28mstr\u001b[39m) -> \u001b[43mList\u001b[49m[LetterFeedback]:\n\u001b[32m      4\u001b[39m     valid_letters = \u001b[38;5;28mset\u001b[39m(secret_word)\n\u001b[32m      5\u001b[39m     feedback = []\n",
      "\u001b[31mNameError\u001b[39m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_feedback(guess: str, secret_word: str) -> List[LetterFeedback]:\n",
    "    valid_letters = set(secret_word)\n",
    "    feedback = []\n",
    "    for letter, secret_letter in zip(guess, secret_word):\n",
    "        if letter == secret_letter:\n",
    "            feedback.append(LetterFeedback.CORRECT)\n",
    "        elif letter in valid_letters:\n",
    "            feedback.append(LetterFeedback.WRONG_POS)\n",
    "        else:\n",
    "            feedback.append(LetterFeedback.WRONG_LETTER)\n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48252c1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnext_turn\u001b[39m(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     past_guesses: \u001b[43mList\u001b[49m[GuessWithFeedback], \n\u001b[32m      3\u001b[39m     secret_word: \u001b[38;5;28mstr\u001b[39m, \n\u001b[32m      4\u001b[39m     adapter_id = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m ):\n\u001b[32m      6\u001b[39m     prompt = render_prompt(past_guesses)\n\u001b[32m      7\u001b[39m     completion = generate_stream(prompt, adapter_id)\n",
      "\u001b[31mNameError\u001b[39m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "def next_turn(\n",
    "    past_guesses: List[GuessWithFeedback], \n",
    "    secret_word: str, \n",
    "    adapter_id = \"\"\n",
    "):\n",
    "    prompt = render_prompt(past_guesses)\n",
    "    completion = generate_stream(prompt, adapter_id)\n",
    "    match = re.search(\n",
    "        r\"<guess>\\s*(.*?)\\s*</guess>\", completion, re.DOTALL\n",
    "    )\n",
    "    if not match:\n",
    "        raise RuntimeError(\"invalid guess\")\n",
    "    \n",
    "    guess = match.group(1).upper()\n",
    "    feedback = get_feedback(guess, secret_word)\n",
    "    past_guesses.append(GuessWithFeedback(guess, feedback))\n",
    "    print(\"\\n\\n\")\n",
    "    print((\"-\" * 100) + \"\\n\")\n",
    "    for past_guess in past_guesses:\n",
    "        print(past_guess)\n",
    "    \n",
    "    if guess == secret_word:\n",
    "        print(\"üéâ SUCCESS üéâ\")\n",
    "    elif len(past_guesses) >= 6:\n",
    "        print(\"‚ùå better luck next time... ‚ùå\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1dd9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_word = \"BRICK\"\n",
    "past_guesses = []\n",
    "adapter_id = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cebb502",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a1b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_word = \"BRICK\"\n",
    "past_guesses = []\n",
    "adapter_id = \"wordle-dlai/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8b33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
